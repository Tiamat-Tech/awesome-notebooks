{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f306ae-4b26-4379-b0e3-d1672ecbe4dd",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"YahooFinance.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/YahooFinance.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb6fae7-6f41-4d10-a685-d625ef84d311",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "# YahooFinance - Chat about Amgen trends and predictions\n",
    "<a href=\"https://bit.ly/3JyWIk6\">Give Feedback</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=YahooFinance+-+Chat+about+Amgen+trends+and+predictions:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8180693-37e6-4430-965d-b620fb48c68b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #yahoo #finance #ai #chat #plugin #python #amgn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdaafdd-4393-47d9-a369-728eb8623e8a",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Jeremy Ravenel](https://www.linkedin.com/in/jeremyravenel/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c19bd-73b1-4576-95f0-29e5759974e6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2023-08-31 (Created: 2023-08-31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259bb40b-f791-4b7d-a289-9c8552654c8f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Description:** This notebook will generate an Naas Chat plugin for YahooFinance for Amgen. It uses Python to access the YahooFinance API, NewsAPI, create one big table with actual, predictions, news, and sentiment and output a plugin that can be used to answer questions about the stock performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1722ce3-79bb-45ad-b8ae-3ac6c4c3d1c3",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**References:**\n",
    "- [YahooFinance Naas driver](https://pypi.org/project/naas-drivers/)\n",
    "- [NLTK for sentiment analysis](https://github.com/cjhutto/vaderSentiment)\n",
    "- [NewsAPI for latest news query](https://newsapi.org/docs)\n",
    "- [OpenAI API](https://platform.openai.com/docs/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17064b3-00b5-4d71-96ba-38c6af450919",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f5e20-bcfc-4ceb-83ad-0856868327a0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd368ba3-fc40-46db-af1d-a62d11573923",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import naas\n",
    "import pandas as pd\n",
    "from naas_drivers import prediction, yahoofinance, plotly, newsapi\n",
    "import plotly.graph_objects as go\n",
    "import markdown2\n",
    "from datetime import datetime\n",
    "from IPython.core.display import display, HTML\n",
    "try: \n",
    "    import nltk\n",
    "except:\n",
    "    !pip install nltk --user\n",
    "    import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import json\n",
    "try:\n",
    "    import tiktoken\n",
    "except:\n",
    "    !pip install tiktoken --user\n",
    "    import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79126baa-2a38-4861-8130-66b4c4e13621",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Setup variables\n",
    "**Mandatory**\n",
    "- `ticker_name`: This is a variable that represents the full name of a specific company's stock.\n",
    "- `ticker`: This variable holds the unique series of letters assigned to a security for trading purposes.\n",
    "- `index_name`: This variable represents the name of a specific stock market index.\n",
    "- `index`: This variable holds the unique symbol of a specific stock market index.\n",
    "\n",
    "**Optional**\n",
    "- `date_from`: This is an optional variable that indicates the starting date for a range of dates.\n",
    "- `date_to`: This variable represents the end date of a range.\n",
    "- `data_points`: This variable represents the number of data points that will be predicted in the future.\n",
    "- `output_dir`: This variable represents the directory where the output files will be stored.\n",
    "- `now`: This variable holds the current date and time in a specific format.\n",
    "- `csv_output`: This variable represents the path of the output file in CSV format.\n",
    "- `image_output`: This variable represents the path of the output file in image format.\n",
    "- `html_output`: This variable represents the path of the output file in HTML format.\n",
    "- `tracker_output`: This variable represents the path of the tracker output file in CSV format.\n",
    "- `plugin_name`: This variable represents name of the plugin.\n",
    "- `plugin_output`: This variable represents the path of the plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-pearl",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mandatory\n",
    "ticker_name = \"Amgen\"\n",
    "ticker = \"AMGN\"\n",
    "index_name = \"Nasdaq\" #in this case Nasdaq\n",
    "index = \"^IXIC\" #in this case Nasdaq\n",
    "\n",
    "# Optional\n",
    "date_from = -270\n",
    "date_to = \"today\"\n",
    "data_points = 90 #number of data points predicted in the future\n",
    "output_dir = ticker\n",
    "now = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "csv_output = path.join(output_dir, f\"{now}_{ticker}.csv\")\n",
    "image_output = path.join(output_dir, f\"{now}_{ticker}.png\")\n",
    "html_output = path.join(output_dir, f\"{now}_{ticker}.html\")\n",
    "tracker_output = path.join(output_dir, f\"{now}_{ticker}_tracker.csv\")\n",
    "plugin_name = f\"YahooFinance - Chat about {ticker_name} trends and predictions\"\n",
    "plugin_output = (path.join(output_dir, f\"{plugin_name}.json\")).replace(\" \", \"_\").replace(\"-\", \"_\").upper()\n",
    "\n",
    "# Create output dir\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b9a046-0559-444c-916a-dfe5fe385edc",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-allocation",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get dataset from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-ensemble",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the Stock data\n",
    "df_yahoo = yahoofinance.get(\n",
    "    tickers=ticker,\n",
    "    date_from=date_from,\n",
    "    date_to=date_to\n",
    ").dropna().reset_index(drop=True)\n",
    "\n",
    "# Calculate the rolling minimum and maximum values of the 'total_predict' column\n",
    "df_yahoo['min_rolling'] = df_yahoo['Close'].rolling(window=20).min()\n",
    "df_yahoo['max_rolling'] = df_yahoo['Close'].rolling(window=20).max()\n",
    "\n",
    "# Capitalize all column names\n",
    "df_yahoo.columns = df_yahoo.columns.str.upper()\n",
    "\n",
    "# Display dataframe\n",
    "df_yahoo.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf751ac-8af1-4370-80b1-af7f48b0e921",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Add relative index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de7a1e-019d-4f4c-a1d3-91b057115cb3",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the Index data\n",
    "relative_index_data = yahoofinance.get(\n",
    "    tickers=index,\n",
    "    date_from=date_from,\n",
    "    date_to=date_to\n",
    ").dropna().reset_index(drop=True)\n",
    "\n",
    "# Calculate the relative strength\n",
    "df_yahoo['RELATIVE_INDEX'] = relative_index_data['Close']\n",
    "df_yahoo['RELATIVE_STRENGTH_BASE'] = (df_yahoo['CLOSE'] / relative_index_data['Close']) \n",
    "# Calculate the relative strength percentage\n",
    "df_yahoo['RELATIVE_STRENGTH'] = df_yahoo['CLOSE'] * ( 1 - df_yahoo['RELATIVE_STRENGTH_BASE'])\n",
    "\n",
    "# Display dataframe\n",
    "df_yahoo.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-abuse",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create tracker data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c687f056-3a57-4f9e-9bdd-c790ae55e0d9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_variation(df, ticker):\n",
    "    df_yahoo = df.sort_values(\"DATE\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Get value and date comp\n",
    "    datanow = df_yahoo.loc[0, \"CLOSE\"]\n",
    "    date_now = df_yahoo.loc[0, \"DATE\"]\n",
    "    datayesterday = df_yahoo.loc[1, \"CLOSE\"]\n",
    "\n",
    "    # Calc variation in value and %\n",
    "    varv = datanow - datayesterday\n",
    "    varp = (varv / datanow) * 100\n",
    "\n",
    "    # Get min and max value\n",
    "    min_value = df_yahoo[\"CLOSE\"].min()\n",
    "    max_value = df_yahoo[\"CLOSE\"].max()\n",
    "    \n",
    "    # Calculate the score\n",
    "    score = 0 + ((10 - 0) * (datanow - min_value) / (max_value - min_value))\n",
    "\n",
    "    # Format result\n",
    "    datanow = \"${:,.2f}\".format(round(datanow, 1))\n",
    "    datayesterday = \"${:,.2f}\".format(round(datayesterday, 1))\n",
    "    varv = \"{:+,.2f}\".format(varv)\n",
    "    varp = \"{:+,.2%}\".format(varp / 100)  # dividing by 100 to undo the earlier multiplication by 100\n",
    "    min_value = \"${:,.2f}\".format(round(min_value, 1))\n",
    "    max_value = \"${:,.2f}\".format(round(max_value, 1))\n",
    "\n",
    "    # Create a DataFrame to hold the results\n",
    "    result_df = pd.DataFrame({\n",
    "        \"ENTITY\": \"Universal Tracker\",\n",
    "        \"SCENARIO\": [date_now],\n",
    "        \"INDICATOR\": [ticker],\n",
    "        \"TYPE\": \"Financial\",\n",
    "        \"SOURCE\": \"Yahoo Finance\",\n",
    "        \"VALUE\": [datanow],\n",
    "        \"MIX\": [min_value],\n",
    "        \"MAX\": [max_value],\n",
    "        \"SCORE\": [round(score, 2)]\n",
    "    })\n",
    "\n",
    "    return result_df\n",
    "\n",
    "df_tracker = get_variation(df_yahoo, ticker)\n",
    "df_tracker.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf08bfc-bd3f-4d52-bacb-3a0e73ea4a21",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Add prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-sponsorship",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_predict = prediction.get(\n",
    "    dataset=df_yahoo,\n",
    "    date_column='DATE',\n",
    "    column=\"CLOSE\",\n",
    "    data_points=data_points,\n",
    "    prediction_type=\"all\"\n",
    ").sort_values(\"DATE\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Create 'TOTAL_PREDICT' column\n",
    "df_predict['TOTAL_PREDICT'] = df_predict['LINEAR'].where(df_predict['LINEAR'].notna(), df_predict['CLOSE'])\n",
    "\n",
    "# Calculate the 20 and 50 day moving averages\n",
    "df_predict['MA05'] = df_predict['TOTAL_PREDICT'].rolling(window=5).mean()\n",
    "df_predict['MA10'] = df_predict['TOTAL_PREDICT'].rolling(window=10).mean()\n",
    "df_predict['MA50'] = df_predict['TOTAL_PREDICT'].rolling(window=50).mean()\n",
    "\n",
    "# Display dataframe\n",
    "df_predict.head(int(data_points)+5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee5647-855f-4e84-826b-bcdee1578480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T11:59:10.938077Z",
     "iopub.status.busy": "2023-08-27T11:59:10.937851Z",
     "iopub.status.idle": "2023-08-27T11:59:10.940875Z",
     "shell.execute_reply": "2023-08-27T11:59:10.940219Z",
     "shell.execute_reply.started": "2023-08-27T11:59:10.938055Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Get news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e254938-3a10-4b2b-9c6c-c0b383dac379",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_news = newsapi.connect().get(\n",
    "    f\"{ticker_name}\", \n",
    "    fields=[\"date\",\"title\", \"image\", \"link\", \"description\"]\n",
    ")\n",
    "df_news['date'] = pd.to_datetime(df_news['date']).dt.date\n",
    "df_news= df_news.dropna()\n",
    "print(\"News:\", len(df_news))\n",
    "df_news.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3c0ad-76ef-465e-a422-3a6fb4a8db5f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Analyze sentiment per news article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6207759-46cb-42dc-8ea7-032dd331d60d",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dowload varder/nltk lexicon to perform sentiment analysis\n",
    "nltk.download('vader_lexicon') \n",
    "\n",
    "# Create sentiment analysis\n",
    "def analyze_sentiment(df, columns):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for column in columns:\n",
    "        new_cols = [\n",
    "            f'{column}_neg', \n",
    "            f'{column}_neu', \n",
    "            f'{column}_pos', \n",
    "            f'{column}_compound'\n",
    "        ]\n",
    "        df[new_cols] = df[column].apply(lambda x: pd.Series(sid.polarity_scores(x)))\n",
    "        \n",
    "    df = df.sort_values(by=\"date\", ascending=False)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "# Call the function\n",
    "df_sentiment = analyze_sentiment(df_news, ['title', 'description'])\n",
    "df_sentiment.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e500b-23fd-460c-aafe-6a1a29529f44",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Compute sentiments stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee324c72-318d-4564-b779-418ea5e1db2f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate sentiment stats\n",
    "def calculate_sentiment(df, columns):\n",
    "    for column in columns:\n",
    "        # Calculate sums\n",
    "        neg = df[f'{column}_neg'].sum().round(2)\n",
    "        neu = df[f'{column}_neu'].sum().round(2)\n",
    "        pos = df[f'{column}_pos'].sum().round(2)\n",
    "        compound = df[f'{column}_compound'].sum().round(2)\n",
    "\n",
    "        # Calculate total\n",
    "        total = neg + neu + pos + compound\n",
    "\n",
    "        # Calculate percentages\n",
    "        neg_percent = (neg / total * 100).round(2)\n",
    "        neu_percent = (neu / total * 100).round(2)\n",
    "        pos_percent = (pos / total * 100).round(2)\n",
    "        compound_percent = (compound / total * 100).round(2)\n",
    "\n",
    "        # Append sums and percentages to df\n",
    "        df = df.append(\n",
    "            {\n",
    "                f'{column}_neg': neg,\n",
    "                f'{column}_neu': neu,\n",
    "                f'{column}_pos': pos,\n",
    "                f'{column}_compound': compound,\n",
    "                f'{column}_neg_percent': neg_percent,\n",
    "                f'{column}_neu_percent': neu_percent, \n",
    "                f'{column}_pos_percent': pos_percent,\n",
    "                f'{column}_compound_percent': compound_percent\n",
    "            }, \n",
    "            ignore_index=True\n",
    "        )\n",
    "        \n",
    "        # Create global stats\n",
    "        df['total_neg'] = df['title_neg'] + df['description_neg']  \n",
    "        df['total_neu'] = df['title_neu'] + df['description_neu']  \n",
    "        df['total_pos'] = df['title_pos'] + df['description_pos']  \n",
    "        df['total_compound'] = df['title_compound'] + df['description_compound']  \n",
    "    return df\n",
    "\n",
    "# Call the function\n",
    "df_news_stats = calculate_sentiment(df_sentiment, ['title', 'description'])\n",
    "df_news_stats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a12593-464a-4ccd-a057-ab224d4e6c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T12:20:25.434767Z",
     "iopub.status.busy": "2023-08-27T12:20:25.434515Z",
     "iopub.status.idle": "2023-08-27T12:20:25.437528Z",
     "shell.execute_reply": "2023-08-27T12:20:25.436847Z",
     "shell.execute_reply.started": "2023-08-27T12:20:25.434723Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Sum sentiment by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7d6ad-3d36-499e-ab7c-56211cdc518f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate sums for 'title' and 'description'\n",
    "title_neg = df_news_stats.title_neg.sum()\n",
    "title_neu = df_news_stats.title_neu.sum()\n",
    "title_pos = df_news_stats.title_pos.sum()\n",
    "title_compound = df_news_stats.title_compound.sum()\n",
    "\n",
    "desc_neg = df_news_stats.description_neg.sum()\n",
    "desc_neu = df_news_stats.description_neu.sum()\n",
    "desc_pos = df_news_stats.description_pos.sum()\n",
    "desc_compound = df_news_stats.description_compound.sum()\n",
    "\n",
    "# Calculate total sums\n",
    "total_neg = round(title_neg + desc_neg, 2)\n",
    "total_neu = round(title_neu + desc_neu, 2)\n",
    "total_pos = round(title_pos + desc_pos, 2)\n",
    "total_compound = round(title_compound + desc_compound, 2)\n",
    "\n",
    "# Calculate percentage contribution of each category\n",
    "neg_percent = (total_neg / (total_neg + total_neu + total_pos + total_compound) * 100).round(2)\n",
    "neu_percent = (total_neu / (total_neg + total_neu + total_pos + total_compound) * 100).round(2)\n",
    "pos_percent = (total_pos / (total_neg + total_neu + total_pos + total_compound) * 100).round(2)\n",
    "compound_percent = (total_compound / (total_neg + total_neu + total_pos + total_compound) * 100).round(2)\n",
    "\n",
    "# Preview of what will be sent by email:\n",
    "print(f\"Sum of news sentiment by category:\")\n",
    "print(\n",
    "    \"\\n\\t🔴 Negative \\t\",\n",
    "    total_neg,\n",
    "    f\"({neg_percent}%)\",\n",
    "    \"\\n\\t🟠 Neutral\\t\",\n",
    "    total_neu,\n",
    "    f\"({neu_percent}%)\",\n",
    "    \"\\n\\t🟢 Positive \\t\",\n",
    "    total_pos,\n",
    "    f\"({pos_percent}%)\",\n",
    "    \"\\n\\t🔵 Compound \\t\",\n",
    "    total_compound,\n",
    "    f\"({compound_percent}%)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910b4869-0166-4f97-90f8-681cd74b2ac2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Merge the stock and news dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb447a67-df12-4f91-a9cc-36ca8bc78af1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean datasets\n",
    "df_news_stats.columns = df_news_stats.columns.str.upper()\n",
    "\n",
    "# Format date\n",
    "df_news_stats['DATE'] = pd.to_datetime(df_news_stats['DATE'])\n",
    "df_predict['DATE'] = pd.to_datetime(df_predict['DATE'])\n",
    "\n",
    "# Merge dataframes to create one big table\n",
    "df_obt = pd.merge(df_predict, df_news_stats, on='DATE', how='left')\n",
    "df_obt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aec569-1805-4cd0-a1d8-9ebd029545b2",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Save master table to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e66501b-dbab-4366-9d97-5eaa52ea6a32",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_obt.to_csv(csv_output, index=False)\n",
    "\n",
    "link_csv = naas.asset.add(csv_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-boards",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create graph with trends and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-toyota",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plotly.linechart(\n",
    "    df_obt,\n",
    "    x=\"DATE\",\n",
    "    y=[\"CLOSE\", \"LINEAR\",\"RELATIVE_STRENGTH\", \"MA05\", \"MA10\", \"MA50\", \"MAX_ROLLING\", \"MIN_ROLLING\"],\n",
    "    showlegend=True,\n",
    "    title = f'''<b><span style='font-size: 20px;'>{ticker_name} Trends & Prediction +{str(data_points)} days</span></b>\n",
    "    <br><span style='font-size: 10px;'><b>News Analysis:</b> Negative: {total_neg} ({neg_percent}%), Neutral: {total_neu} ({neu_percent}%), Positive: {total_pos} ({pos_percent}%), Compound: {total_compound} ({compound_percent}%)</span>\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac151803-c0f8-4ada-b6d9-ce88c69f2ef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-25T15:05:55.410069Z",
     "iopub.status.busy": "2022-04-25T15:05:55.409689Z",
     "iopub.status.idle": "2022-04-25T15:05:55.412745Z",
     "shell.execute_reply": "2022-04-25T15:05:55.412096Z",
     "shell.execute_reply.started": "2022-04-25T15:05:55.410037Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Save and share graph in PNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bc374d-791e-4ab8-9f32-bc6785b60496",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save your graph in PNG\n",
    "fig.write_image(image_output)\n",
    "\n",
    "# Share output with naas\n",
    "link_image = naas.asset.add(image_output, params={\"inline\": True})\n",
    "\n",
    "#-> Uncomment the line below to remove your asset\n",
    "# naas.asset.delete(image_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085d0100-c328-4f11-a65e-3f716f1b360a",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7e3af-7941-40a6-b3b9-ccdac5c7ba44",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Create Naas Chat plugin\n",
    "We used Playground to refined the system prompt: https://platform.openai.com/playground?mode=chat&model=gpt-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddda7c6d-bb4e-4eed-b0f2-13c235e63d98",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def create_plugin(\n",
    "    file_path,\n",
    "    name,\n",
    "    model,\n",
    "    temperature,\n",
    "    max_tokens,\n",
    "    system_prompt,\n",
    "):\n",
    "    \n",
    "    # Check tokens count on system_prompt\n",
    "    system_prompt_tokens = num_tokens_from_string(system_prompt, \"cl100k_base\")\n",
    "    if system_prompt_tokens > max_tokens * 0.2:\n",
    "        print(f\"⚠️ Be carefull, your system prompt looks too big. Tokens: {system_prompt_tokens} ({int(max_tokens * 0.2)})\")\n",
    "    else:\n",
    "        print(f\"✅ System prompt tokens count OK: {system_prompt_tokens} (Max recommanded: {int(max_tokens * 0.2)})\")\n",
    "    \n",
    "    # Create json\n",
    "    plugin = {\n",
    "        \"name\": name,\n",
    "        \"model\": model,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"prompt\": system_prompt,\n",
    "    }\n",
    "    \n",
    "    # Save json to file\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(plugin, f)\n",
    "    return file_path\n",
    "\n",
    "model = \"gpt-3.5-turbo-16k\"\n",
    "temperature = 0\n",
    "max_tokens = 16384\n",
    "system_prompt = \"\"\"\n",
    "You are Abi, experience trader in the NY Stock Exchange. You want to analyze the stock of [TICKER]. \n",
    "Start by presenting youself.\n",
    "Always display the graph in markdown about the [TICKER] trends and predictions: [LINK_IMAGE] and the CSV of all data computed to download and analyze in further details: [LINK_CSV]\n",
    "Present the latest news on [TICKER].\n",
    "\n",
    "Stock data: [STOCK]\n",
    "News data: [DATA]\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = system_prompt.replace(\"[TICKER]\", ticker)\n",
    "system_prompt = system_prompt.replace(\"[LINK_IMAGE]\", link_image)\n",
    "system_prompt = system_prompt.replace(\"[LINK_CSV]\", link_csv)\n",
    "system_prompt = system_prompt.replace(\"[DATA]\", df_news.to_string(index=False))\n",
    "system_prompt = system_prompt.replace(\"[STOCK]\", df_tracker.to_string(index=False))\n",
    "\n",
    "plugin_path = create_plugin(\n",
    "    plugin_output,\n",
    "    plugin_name,\n",
    "    model,\n",
    "    temperature,\n",
    "    max_tokens,\n",
    "    system_prompt,\n",
    ")\n",
    "print(\"✅ Plugin path:\", plugin_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec945155-5ccd-465a-b7ab-8e8d0bdc4989",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Save plugin as naas asset\n",
    "You can now use in your MyChatGPT by copy/pasting the URL after the command `/use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc902de-1563-419f-b18c-05c642730cf3",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "naas.asset.add(plugin_path, params={\"inline\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830ca77-e61d-4f68-912e-943b05d391e4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "33b5fb710b3ab35effbacf6ca747ef7544f8018bbe23f9263d94e862d3ed9fdb",
   "notebook_path": "YahooFinance/YahooFinance_Chat_about_Amgen_trends_and_predictions.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.3.3"
  },
  "toc-autonumbering": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}