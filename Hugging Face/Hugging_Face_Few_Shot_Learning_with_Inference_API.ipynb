{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bedfa998",
   "metadata": {
    "id": "G8G4XdnudkS6",
    "papermill": {},
    "tags": []
   },
   "source": [
    "<img width=\"8%\" alt=\"Hugging Face.png\" src=\"https://raw.githubusercontent.com/jupyter-naas/awesome-notebooks/master/.github/assets/logos/Hugging%20Face.png\" style=\"border-radius: 15%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff8007-4a9b-425f-a5f1-892655a5de9b",
   "metadata": {
    "id": "cziuXC9hduys",
    "papermill": {},
    "tags": []
   },
   "source": [
    "# Hugging Face - Few Shot Learning with Inference API\n",
    "<a href=\"https://bit.ly/3JyWIk6\">Give Feedback</a> | <a href=\"https://github.com/jupyter-naas/awesome-notebooks/issues/new?assignees=&labels=bug&template=bug_report.md&title=Hugging+Face+-+Few+Shot+Learning+with+Inference+API:+Error+short+description\">Bug report</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9776f972",
   "metadata": {
    "id": "CLPRc-MJd982",
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Tags:** #huggingface #ml #few_shot_learning #prompt #inference_api #ai #text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ddb4e8",
   "metadata": {
    "id": "9TxAcynceEXm",
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Author:** [Saurabh Arjun Sawant](https://www.linkedin.com/in/srsawant34/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2e9ee-568e-43bd-a598-f55404b06ab6",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "**Last update:** 2023-11-08 (Created: 2023-11-08)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naas-description",
   "metadata": {
    "papermill": {},
    "tags": [
     "description"
    ]
   },
   "source": [
    "**Description:** This notebook demonstrates how to utilize the <a href=\"https://huggingface.co/docs/inference-endpoints/index\">inference endpoints</a> (additional information can be found here: <a href=\"https://huggingface.co/docs/api-inference/index#-hosted-inference-api\">link</a>) of hugging face models. Additionally, it demonstrates how to use few shot learning for a specific task in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f0816",
   "metadata": {
    "id": "I5qfxShzjrJK",
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b53a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T22:06:30.070094Z",
     "iopub.status.busy": "2022-11-02T22:06:30.069794Z",
     "iopub.status.idle": "2022-11-02T22:06:30.072975Z",
     "shell.execute_reply": "2022-11-02T22:06:30.072331Z",
     "shell.execute_reply.started": "2022-11-02T22:06:30.070062Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d1eac5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWQbKgcncvLE",
    "outputId": "218bfc13-27fd-4331-b3c3-304c7986a0b1",
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7133c",
   "metadata": {
    "id": "qGxt0Sy1lQlL",
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f89fd4",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import naas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d3834b",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Add the Model and API token\n",
    "\n",
    "#### Steps to get API token\n",
    "- Create an account on [Hugging Face](https://huggingface.co)\n",
    "- Log in, and click on profile icon (top right corner)\n",
    "- Go to settings\n",
    "- Click on [Access tokens](https://huggingface.co/settings/tokens)\n",
    "- Now, create a new access token with name: `GPT_INFERENCE` and role: `read`\n",
    "- Copy the generated token and paste it below\n",
    "\n",
    "We use GPT based models since they excel in few-shot learning due to their ability to generate coherent and contextually relevant responses based on limited examples, capturing relationships in data more effectively than many other large language models.\n",
    "In this demonstration, we will utilize the <a href=\"https://huggingface.co/EleutherAI/gpt-neo-1.3B\">gpt-neo-1.3B</a> model; additional GPT-based models can be explored <a href=\"https://huggingface.co/EleutherAI\">here</a>. Developed by <a href=\"https://www.eleuther.ai/\">EleutherAI</a>, GPT⁠-⁠Neo is a series of transformer-based language models built on the GPT architecture. EleutherAI aims to create a model of GPT⁠-⁠3's scale and provide open access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02938f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment to store the environment variable in Naas cloud\n",
    "# naas.secret.add(\"GPT_INFERENCE\", \"Paste_token_here\")\n",
    "\n",
    "# Set the environment variables\n",
    "MODEL = \"EleutherAI/gpt-neo-1.3B\"\n",
    "API_TOKEN = naas.secret.get(\"GPT_INFERENCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec280229",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e868fc",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Define function to make API calls to Hugging Face endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c02550",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query(\n",
    "        payload='', \n",
    "        model = MODEL,\n",
    "        parameters = {\n",
    "            'max_new_tokens':5,\n",
    "            'temperature': 0.5\n",
    "        }, \n",
    "        options = {\n",
    "            'use_cache': False\n",
    "        }\n",
    "    ):\n",
    "    API_URL = f\"https://api-inference.huggingface.co/models/{model}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "    body = {\"inputs\":payload,'parameters':parameters,'options':options}\n",
    "    \n",
    "    try:\n",
    "        response = requests.request(\"POST\", API_URL, headers=headers, data= json.dumps(body))\n",
    "        return response.json()[0]['generated_text']\n",
    "    except:\n",
    "        return \"Error: \" + \" \".join(response.json()['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378de1e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-02T22:04:21.973105Z",
     "iopub.status.busy": "2022-11-02T22:04:21.972816Z",
     "iopub.status.idle": "2022-11-02T22:04:21.980111Z",
     "shell.execute_reply": "2022-11-02T22:04:21.977454Z",
     "shell.execute_reply.started": "2022-11-02T22:04:21.973076Z"
    },
    "papermill": {},
    "tags": []
   },
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0724801-389c-4184-b3a1-a3491573e24e",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "><b>The model usually takes time to load in the hugging face server. For example, model gpt-neo-1.3B takes approximately 212 seconds</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0a8f9",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Zero-shot\n",
    "\n",
    "Zero-shot learning means to generate meaningful responses from model for tasks or topics it has never been explicitly trained on, showcasing a capacity to generalize and understand novel concepts without specific examples during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc20e20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9yETPBqgoWpO",
    "outputId": "062820d9-a750-45ea-b263-ec617df962d6",
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Sentence: I loved todays movie.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = query(payload=prompt, model=MODEL)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f24f731",
   "metadata": {
    "id": "zaufheoZo4mf",
    "papermill": {},
    "tags": []
   },
   "source": [
    "### One-shot\n",
    "\n",
    "One-shot learning refers to the model's ability to understand and generate meaningful responses after being exposed to a single example or prompt during the inference phase, showcasing its capacity to generalize knowledge from limited input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e3ccf1",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Sentence: I loved todays movie.\n",
    "Sentiment: positive\n",
    "\n",
    "#####\n",
    "\n",
    "Sentence: I didn't like the action.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = query(payload=prompt, model=MODEL)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96831b89-e92f-4ddb-8703-0124c26c8613",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Two-shot\n",
    "\n",
    "Similar to one-shot, we will have the model exposed to two examples to generalize knowledge and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b6be0-c30a-4f70-93c4-b993558e741f",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Sentence: I loved todays movie.\n",
    "Sentiment: positive\n",
    "\n",
    "#####\n",
    "\n",
    "Sentence: I didn't like the action.\n",
    "Sentiment: negative\n",
    "\n",
    "#####\n",
    "\n",
    "Sentence: Liked the direction and scene settings.\n",
    "Sentiment: \"\"\"\n",
    "\n",
    "response = query(payload=prompt, model=MODEL)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89831a-ccd8-4e78-b140-f69a94c6af12",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "source": [
    "### Few-shot learning with custom dataset\n",
    "\n",
    "You can also use any custom dataset and generate prompts like above. For example, below we will use <a href=\"https://huggingface.co/datasets/carblacac/twitter-sentiment-analysis\">twitter-sentiment-analysis</a>. More datasets in huggingface can be found <a href=\"https://huggingface.co/datasets\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a322b-3967-42f3-a77d-720d1308a998",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt_with_examples(data, target_col, num_of_examples = 0):\n",
    "    examples = np.random.choice(data, num_of_examples + 1)\n",
    "    prompts = []\n",
    "    for example in examples:\n",
    "        review = example[\"text\"]\n",
    "        sentiment = \"positive\" if example[target_col] else \"negative\"\n",
    "        prompt = f\"Sentence: {review}\\nSentiment: {sentiment}\\n\"\n",
    "        prompts.append(prompt)\n",
    "    return \"\"\"\\n#####\\n\\n\"\"\".join(prompts)[:-9]\n",
    "\n",
    "data = load_dataset('carblacac/twitter-sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4156dc7-b4ce-482b-91bc-759097782b6c",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = generate_prompt_with_examples(data=data['train'], target_col=\"feeling\", num_of_examples=2)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e80171-fb45-495f-99fa-dbb801cec7af",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query(payload=prompt, model=MODEL)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ce2e67-fa35-4986-9dc0-55bbf1726ceb",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "naas": {
   "notebook_id": "a7302332780695583c4a7dea4e5df4f2057fe09eae2003598b6e6585b068bd23",
   "notebook_path": "Hugging Face/Hugging_Face_Few_Shot_Learning_with_Inference_API.ipynb"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "parameters": {},
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}